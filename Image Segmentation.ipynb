{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# from zipfile import ZipFile\n",
    "# from matplotlib import pyplot as py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file = ZipFile('BSR.zip')\n",
    "# file.extractall()\n",
    "# file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    " \n",
    "# test_data_images = []\n",
    "# for i in range(1,201):\n",
    "#         test_data_images.append(py.imread(\"BSR/\"+\"BSDS500/\"+\"data/\"+\"images/\"+\"test/\"+\"s\"+str(i)+\".jpg\"))\n",
    "\n",
    "# print(test_data_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data_images = []\n",
    "# for j in range(1,201):\n",
    "#         train_data_images.append(py.imread(\"BSR/\"+\"BSDS500/\"+\"data/\"+\"images/\"+\"train/\"+\"t\"+str(j)+\".jpg\").reshape(154401,3))\n",
    "\n",
    "        \n",
    "# print(train_data_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(train_data_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# !{sys.executable} -m pip install scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import scipy.io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from scipy.io import loadmat\n",
    "# test_data_ground = []\n",
    "# for k in range(1,201):\n",
    "#     test_data_ground.append(scipy.io.loadmat(\"BSR/\"+\"BSDS500/\"+\"data/\"+\"groundTruth/\"+\"test/\"+\"s\"+str(k)+\".mat\"))\n",
    "    \n",
    "# print(test_data_ground)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data_ground = []\n",
    "# for m in range(1,201):\n",
    "#     train_data_ground.append(scipy.io.loadmat(\"BSR/\"+\"BSDS500/\"+\"data/\"+\"groundTruth/\"+\"train/\"+\"t\"+str(m)+\".mat\"))\n",
    "    \n",
    "# print(train_data_ground)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from matplotlib import image as mpimg\n",
    "# for x in range(0,200):\n",
    "#     img1 = test_data_images[x]\n",
    "#     imgplot1 = py.imshow(img1)\n",
    "#     py.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for k in range(1,201):\n",
    "#     mat = scipy.io.loadmat(\"BSR/\"+\"BSDS500/\"+\"data/\"+\"groundTruth/\"+\"test/\"+\"s\"+str(k)+\".mat\")\n",
    "#     groundTruth = mat.get('groundTruth')\n",
    "#     label_num = groundTruth.size\n",
    "#     for i in range(label_num):\n",
    "#         boundary = groundTruth[0][i][0][0][0]\n",
    "#         mgplot2 = py.imshow(boundary)\n",
    "#         py.figure()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for y in range(0,200):\n",
    "#     img3 = train_data_images[y]\n",
    "#     imgplot3 = py.imshow(img3)\n",
    "#     py.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# boundary=[]\n",
    "# for k in range (0,200):\n",
    "#     boundary.append([])\n",
    "# for k in range(1,201):\n",
    "#     mat = scipy.io.loadmat(\"BSR/\"+\"BSDS500/\"+\"data/\"+\"groundTruth/\"+\"train/\"+\"t\"+str(k)+\".mat\")\n",
    "#     groundTruth = mat.get('groundTruth')\n",
    "#     label_num = groundTruth.size\n",
    "#     for i in range(label_num):\n",
    "#         boundary[k-1] = groundTruth[0][i][0][0][0]\n",
    "#         mgplot2 = py.imshow(boundary[k-1])\n",
    "#         py.figure()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sklearn\n",
    "# from sklearn.cluster import KMeans\n",
    "\n",
    "# train_data_images=np.asarray(train_data_images)\n",
    "# print(train_data_images.shape)\n",
    "# print(train_data_images[1].shape)\n",
    "\n",
    "# kmeans=KMeans(n_clusters=11).fit(np.unique(train_data_images.reshape(200*321*481,3),axis=0))\n",
    "# print(\"done\")\n",
    "# labels=kmeans.labels_\n",
    "# centroids=kmeans.cluster_centers_\n",
    "\n",
    "# print(labels)\n",
    "# print(centroids)\n",
    "# print(train_data_images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clusters=[]\n",
    "# train_data_images2=np.unique(train_data_images.reshape(200*321*481,3),axis=0)\n",
    "# print(train_data_images2.shape)\n",
    "                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(labels[0])\n",
    "# k=11\n",
    "# for i in range(0,k):\n",
    "#     clusters.append([])\n",
    "    \n",
    "# for i in range(0,1260698):\n",
    "#     clusters[labels[i]].append(train_data_images2[i]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import math\n",
    "# mean_of_clusters=[]\n",
    "# for i in range(0,k):\n",
    "#     mean_of_clusters.append([]) \n",
    "# for i in range(0,k):\n",
    "#     mean_of_clusters[i]=np.ceil(np.mean(clusters[i],axis=0))  \n",
    "# print(mean_of_clusters)\n",
    "# mean_of_clusters=np.asarray(mean_of_clusters)\n",
    "# mean_of_clusters.astype(int)\n",
    "# print(mean_of_clusters)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data_images_N=train_data_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels_img=[]\n",
    "# for i in range(0,200):\n",
    "#     labels_img=kmeans.predict(train_data_images_N[i])\n",
    "#     for j in range(0,154401):\n",
    "#         train_data_images_N[i][j]=mean_of_clusters[labels_img[j]]\n",
    "\n",
    "# # for i in range(0,200):\n",
    "# #     for j in range(0,154401):\n",
    "# #         for r in range(0,k):\n",
    "# #             if train_data_images_N[i][j] in clusters[r]:\n",
    "# #                 train_data_images_N[i][j]=mean_of_clusters[r]\n",
    "    \n",
    "# #     train_data_images2[i]=mean_of_clusters[labels[i]]\n",
    "    \n",
    "# # train_data_images2[0]=train_data_images2[0].reshape(321,481,3)\n",
    "\n",
    "# # print(train_data_images_N[0].shape)\n",
    "# # print(train_data_images_N[0])\n",
    "# # for i in range(0,200):\n",
    "# #     img3 = train_data_images_N[i].reshape(321,481,3)\n",
    "# #     imgplot3 = py.imshow(img3)\n",
    "# #     py.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # for i in range(0,200):\n",
    "# #     img3 = train_data_images_N[i].reshape(321,481,3)\n",
    "# #     imgplot3 = py.imshow(img3)\n",
    "# #     py.show()\n",
    "    \n",
    "    \n",
    "# img3 = train_data_images_N[1].reshape(321,481,3)\n",
    "# imgplot3 = py.imshow(img3)\n",
    "# py.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sklearn.metrics.cluster as x\n",
    "# print(train_data_images_N[5].shape)\n",
    "# kmeans1=KMeans(n_clusters=k).fit(train_data_images_N[5])\n",
    "# print(\"done\")\n",
    "# labels1=kmeans1.labels_\n",
    "# print(labels1)\n",
    "\n",
    "# boundary=np.asarray(boundary)\n",
    "# boundary1=boundary[5].reshape(321*481)\n",
    "# print(boundary1.shape)\n",
    "# print(labels1.shape)\n",
    "# contingency=x.contingency_matrix(boundary1,labels1)\n",
    "# print(contingency)\n",
    "# train_data_ground=np.asarray(train_data_ground)\n",
    "# # print(boundary[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # entropy\n",
    "# x=[]\n",
    "# for i in range(0,len(contingency)):\n",
    "#     x.append(0)\n",
    "\n",
    "# entropy=0\n",
    "# for i in range(0,len(contingency)):\n",
    "#     for j in range(0,6):\n",
    "# #         print(j)\n",
    "#         if contingency[i][j]==0:\n",
    "#             continue\n",
    "#         x[i] = x[i]-(contingency[i][j])/np.sum(contingency[i,:])*math.log((contingency[i][j])/np.sum(contingency[i,:]),2)\n",
    "        \n",
    "# for i in range(0,len(contingency)):\n",
    "#     entropy=entropy+x[i]*(np.sum(contingency[i,:])/np.sum(contingency[i,:]))\n",
    "    \n",
    "    \n",
    "# print(entropy)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(boundary1))\n",
    "# print(len(contingency))\n",
    "# print(contingency[0][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # f measure\n",
    "\n",
    "# import scipy.spatial.distance as sc\n",
    "\n",
    "# f=0\n",
    "\n",
    "# for i in range (0,k):\n",
    "#     prec=np.max(contingency[i,:])/np.sum(contingency[i,:])\n",
    "#     ji=np.argmax(contingency[i,:])\n",
    "#     rec=np.sum(contingency[i,ji])/np.sum(contingency[i,ji])\n",
    "#     f=f+((prec*rec))/(prec+rec)\n",
    "    \n",
    "# f=f/k\n",
    "# print(f)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # K Mean\n",
    "# import random\n",
    "# import numpy as np\n",
    "# import math\n",
    "# def Kmeans_evaluation(data,k,iterator,centroids):\n",
    "    \n",
    "#     clusters=[]\n",
    "#     data_copied=[]\n",
    "#     data_copied=np.copy(data)\n",
    "#     np.random.shuffle(data_copied)\n",
    "#     ##initially randomizing the centroids\n",
    "#     if (iterator==1):\n",
    "#         centroids=[]\n",
    "#         for i in range(0,k):\n",
    "#             centroids.append([]) \n",
    "#         print(\"centroids\")\n",
    "#         for i in range(0,k):\n",
    "#             centroids[i]=random.choice(data_copied[i])\n",
    "#             print(centroids[i].shape)\n",
    "#     print(\"centroids done\")\n",
    "#     print(len(centroids))\n",
    "#     for i in range(0,k):\n",
    "#         clusters.append([]) \n",
    "#     print(\"data\")\n",
    "#     print(len(data))\n",
    "#     for i in range(1,len(data)):\n",
    "#     ##return the index of the nearest centroid to each point\n",
    "#         index=np.argmin(np.linalg.norm(centroids-data[i][i],axis=1))\n",
    "#         print(\"index:\")\n",
    "#         print(index)\n",
    "#         ##creating new clusters\n",
    "#         clusters[index].append(data[i])\n",
    "       \n",
    "    \n",
    "    \n",
    "#     for i in range(0,k):\n",
    "#         print(clusters[i])\n",
    "    \n",
    "#     centroids_temp=np.copy(centroids)\n",
    "#     ##finding new centroids    \n",
    "#     for i in range(0,k):\n",
    "#         for j in range(0,154401):\n",
    "#             centroids_temp[i]=np.mean(clusters[i],axis=1)\n",
    "#     print(centroids_temp[i])\n",
    "    \n",
    "#     iterator=iterator+1\n",
    "#     print(\"iteration end\")\n",
    "#     flag=0\n",
    "#     print(centroids_temp[i])\n",
    "#     print(centroids[i])\n",
    "#     for i in range(0,k):\n",
    "#         if np.array_equal(centroids[i],centroids_temp[i])==False:\n",
    "#             flag=1\n",
    "#             break\n",
    "#     if flag==1:\n",
    "#         print(\"new ieration\")\n",
    "#         Kmeans_evaluation(data,k,iterator,centroids_temp)\n",
    "        \n",
    "#     elif flag==0:\n",
    "#          print(\"end\")\n",
    "#          print(iterator)\n",
    "#          return clusters,centroids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # D=np.array([[5,8],[10,8],[11,8],[6,7],[10,7],[12,7],[13,7],[5,6],[10,6],[13,6],\n",
    "# # [6,5],[9,4],[11,5],[14,6],[15,5],[2,4],[3,4],[5,4],[6,4],[7,4],[15,4],[3,3]\n",
    "# # ,[7,3],[8,2]])\n",
    "# # train_data_images = np.asarray(train_data_images)\n",
    "# for n in range (0,200):\n",
    "# #     train_data_images[n]=np.asarray(train_data_images[n])\n",
    "#     train_data_images[n]=train_data_images[n].reshape(321*481,3)\n",
    "\n",
    "\n",
    "# print(train_data_images[1].shape)\n",
    "# centroids_km=np.zeros((3,2),dtype=int)\n",
    "# clusters_km=[]\n",
    "# clusters_km,centroids_km=Kmeans_evaluation(train_data_images,3,1,0)\n",
    "\n",
    "# print(clusters_km)\n",
    "\n",
    "\n",
    "\n",
    "# # centroids_km = centroids\n",
    "\n",
    "# # print(labels1)\n",
    "# # print(centroids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def Con_Table(Clabels,Tlabels,C):\n",
    "  \n",
    "#   r=len(Clabels)\n",
    "#   t=len(Tlabels)\n",
    "  \n",
    "  \n",
    "#   N =np.zeros((r,t),dtype=int)\n",
    "#   for i in range(0,r):\n",
    "#     for j in range(0,t):\n",
    "#       N[i,j]=len(set(Clabels[i]).intersection(set(Tlabels[j]))) \n",
    "#   print('The contingency matrix is ')\n",
    "#   print(N)\n",
    "\n",
    "\n",
    "# # F Measure\n",
    "\n",
    "\n",
    "\n",
    "# # C Entropy\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data_images_E = []\n",
    "# for j in range(1,201):\n",
    "#     train_data_images_temp=py.imread(\"BSR/\"+\"BSDS500/\"+\"data/\"+\"images/\"+\"train/\"+\"t\"+str(j)+\".jpg\")\n",
    "#     temp=train_data_images_temp\n",
    "#     temp=temp.tolist()\n",
    "#     for z in range(0,(train_data_images_temp.shape)[0]):\n",
    "#         for l in range(0,(train_data_images_temp.shape)[1]):            \n",
    "#             temp[z][l].append(z)\n",
    "#             temp[z][l].append(l)            \n",
    "#     temp=np.asarray(temp)\n",
    "#     train_data_images_E.append(temp.reshape(154401,5))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data_images_E=np.asarray(train_data_images_E)\n",
    "# print(train_data_images_E.shape)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data_images_E=np.asarray(train_data_images_E)\n",
    "# print(train_data_images_E.shape)\n",
    "# print(train_data_images_E[1].shape)\n",
    "\n",
    "# kmeans_E=KMeans(n_clusters=3).fit(np.unique(train_data_images_E.reshape(200*321*481,5),axis=0))\n",
    "# print(\"done\")\n",
    "# labels_E=kmeans_E.labels_\n",
    "# centroids_E=kmeans_E.cluster_centers_\n",
    "\n",
    "# print(labels_E)\n",
    "# print(centroids_E)\n",
    "# print(train_data_images_E.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clusters_E=[]\n",
    "# train_data_images2_E=np.unique(train_data_images_E.reshape(200*321*481,5),axis=0)\n",
    "# print(train_data_images2_E.shape)\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(labels_E[0])\n",
    "# k=3\n",
    "# for i in range(0,k):\n",
    "#     clusters_E.append([])\n",
    "    \n",
    "# for i in range(0,(train_data_images2_E.shape)[0]):\n",
    "#     clusters_E[labels_E[i]].append(train_data_images2_E[i]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import math\n",
    "# mean_of_clusters_E=[]\n",
    "# for i in range(0,k):\n",
    "#     mean_of_clusters_E.append([]) \n",
    "# for i in range(0,k):\n",
    "#     mean_of_clusters_E[i]=np.ceil(np.mean(clusters_E[i],axis=0))  \n",
    "# print(mean_of_clusters_E)\n",
    "# mean_of_clusters_E=np.asarray(mean_of_clusters_E)\n",
    "# mean_of_clusters_E.astype(int)\n",
    "# print(mean_of_clusters_E)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data_images_NE=train_data_images_E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels_img_E=[]\n",
    "# for i in range(0,200):\n",
    "#     labels_img_E=kmeans.predict(train_data_images_NE[i])\n",
    "#     for j in range(0,154401):\n",
    "#         train_data_images_NE[i][j]=mean_of_clusters_E[labels_img_E[j]]\n",
    "\n",
    "# # for i in range(0,200):\n",
    "# #     for j in range(0,154401):\n",
    "# #         for r in range(0,k):\n",
    "# #             if train_data_images_N[i][j] in clusters[r]:\n",
    "# #                 train_data_images_N[i][j]=mean_of_clusters[r]\n",
    "    \n",
    "# #     train_data_images2[i]=mean_of_clusters[labels[i]]\n",
    "    \n",
    "# # train_data_images2[0]=train_data_images2[0].reshape(321,481,3)\n",
    "\n",
    "# print(train_data_images_NE[0].shape)\n",
    "# print(train_data_images_NE[0])\n",
    "# for i in range(0,200):\n",
    "#     img3 = train_data_images_NE[i].reshape(321,481,5)\n",
    "#     imgplot3 = py.imshow(img3)\n",
    "#     py.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sklearn.metrics.cluster as x\n",
    "# print(train_data_images_NE[1].shape)\n",
    "# kmeans1_E=KMeans(n_clusters=3).fit(train_data_images_NE[1])\n",
    "# print(\"done\")\n",
    "# labels1_E=kmeans1_E.labels_\n",
    "# print(labels1)\n",
    "\n",
    "# boundary=np.asarray(boundary)\n",
    "# boundary1=boundary[1].reshape(321*481)\n",
    "# print(boundary1.shape)\n",
    "# print(labels1_E.shape)\n",
    "# contingency_E=x.contingency_matrix(boundary1,labels1_E)\n",
    "# print(contingency_E)\n",
    "# train_data_ground=np.asarray(train_data_ground)\n",
    "# # print(boundary[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x=[]\n",
    "# for i in range(0,len(contingency_E)):\n",
    "#     x.append(0)\n",
    "\n",
    "# entropy=0\n",
    "# for i in range(0,len(contingency_E)):\n",
    "#     for j in range(0,k):\n",
    "# #         print(j)\n",
    "#         if contingency_E[i][j]==0:\n",
    "#             continue\n",
    "#         x[i] = x[i]-(contingency_E[i][j])/np.sum(contingency_E[i,:])*math.log((contingency_E[i][j])/np.sum(contingency_E[i,:]),2)\n",
    "        \n",
    "# for i in range(0,len(contingency_E)):\n",
    "#     entropy=entropy+x[i]*(np.sum(contingency_E[i,:])/np.sum(contingency_E[i,:]))\n",
    "    \n",
    "    \n",
    "# print(entropy)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # f measure\n",
    "\n",
    "# import scipy.spatial.distance as sc\n",
    "\n",
    "# f=0\n",
    "\n",
    "# for i in range (0,k):\n",
    "#     prec=np.max(contingency_E[i,:])/np.sum(contingency_E[i,:])\n",
    "#     ji=np.argmax(contingency_E[i,:])\n",
    "#     rec=np.sum(contingency_E[i,ji])/np.sum(contingency_E[i,ji])\n",
    "#     f=f+((prec*rec))/(prec+rec)\n",
    "    \n",
    "# f=f/k\n",
    "# print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data_images_RES = []\n",
    "# for j in range(1,2):\n",
    "#         train_data_images_RES.append(py.imread(\"Resizing/\"+\"t\"+str(j)+\".jpg\").reshape(9600,3))\n",
    "\n",
    "        \n",
    "# print(train_data_images_RES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.cluster import SpectralClustering\n",
    "# from sklearn.neighbors import kneighbors_graph\n",
    "# train_data_images_RES=np.asarray(train_data_images_RES)\n",
    "# train_data_images_RES=train_data_images_RES.reshape(9600,3)\n",
    "# clustering_NC = SpectralClustering(n_neighbors=3).fit(train_data_images_RES)\n",
    "# clustering_NC.labels_\n",
    "\n",
    "\n",
    "# sm = kneighbors_graph(train_data_images_RES,n_neighbors=5)\n",
    "# # sm = sm.toarray()\n",
    "# print(sm)\n",
    "# degree=[]\n",
    "# for v in sm :\n",
    "#     degree.append(np.sum(v))\n",
    "    \n",
    "# print(len(degree))\n",
    "# print(degree)\n",
    "# D = np.diag(degree)\n",
    "# print(D)\n",
    "# L = np.subtract(D,sm)\n",
    "# D_inv = np.linalg.inv(D)\n",
    "# L2 = np.eye(24) - np.matmul(D_inv, sm)\n",
    "# print(L2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
